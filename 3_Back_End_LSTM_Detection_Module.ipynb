{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "#mnist = input_data.read_data_sets('MNIST_data', one_hot=True) # Removed\n",
    "import numpy as np # Included\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from numpy import genfromtxt\n",
    "benign_traffic = genfromtxt('/home/ubuntu/dataset/benign_traffic.csv', delimiter=',')\n",
    "gafgyt_combo = genfromtxt('/home/ubuntu/dataset/gafgyt_combo.csv', delimiter=',')\n",
    "# gafgyt_junk = genfromtxt('/home/ubuntu/dataset/gafgyt_junk.csv', delimiter=',')\n",
    "# gafgyt_scan = genfromtxt('/home/ubuntu/dataset/gafgyt_scan.csv', delimiter=',')\n",
    "# gafgyt_tcp = genfromtxt('/home/ubuntu/dataset/gafgyt_tcp.csv', delimiter=',')\n",
    "# gafgyt_udp = genfromtxt('/home/ubuntu/dataset/gafgyt_udp.csv', delimiter=',')\n",
    "# mirai_ack = genfromtxt('/home/ubuntu/dataset/mirai_ack.csv', delimiter=',')\n",
    "# mirai_scan = genfromtxt('/home/ubuntu/dataset/mirai_scan.csv', delimiter=',')\n",
    "# mirai_syn = genfromtxt('/home/ubuntu/dataset/mirai_syn.csv', delimiter=',')\n",
    "# mirai_udp = genfromtxt('/home/ubuntu/dataset/mirai_udp.csv', delimiter=',')\n",
    "# mirai_udpplain = genfromtxt('/home/ubuntu/dataset/mirai_udpplain.csv', delimiter=',')\n",
    "\n",
    "# with open('/home/ubuntu/dataset/benign_traffic.csv', 'r') as csvfile:\n",
    "\n",
    "#     csvreader = csv.reader(csvfile)\n",
    "#     next(csvreader,None)\n",
    "#     output = open('/home/ubuntu/dataset/corrected_benign_traffic.csv', 'wb')\n",
    "#     writer = csv.writer(output)\n",
    "#     for row in csvreader:\n",
    "#         if row[1].isdigit()==True:\n",
    "#             print(row)\n",
    "#             #writer.writerow(row)\n",
    "#     csvfile.close()\n",
    "#     output.close()\n",
    "\n",
    "#benign_traffic = pd.read_csv(\"/home/ubuntu/dataset/benign_traffic.csv\")\n",
    "\n",
    "#benign_traffic.head()\n",
    "# fx_array=open('Parsed Data/complete_train_rand_xin.npy','rb')\n",
    "# x_in = np.load(fx_array)\n",
    "\n",
    "# fy_array=open('Parsed Data/complete_train_rand_yin.npy','rb')\n",
    "# y_in = np.load(fy_array)\n",
    "\n",
    "# fxt_array=open('Parsed Data/complete_test_rand_xin.npy','rb')\n",
    "# xt_in = np.load(fxt_array)\n",
    "\n",
    "# fyt_array=open('Parsed Data/complete_test_rand_yin.npy','rb')\n",
    "# yt_in = np.load(fyt_array)\n",
    "\n",
    "\n",
    "# print(\"Normal Sample: \\n\")\n",
    "# print(\" Method: 0\\n \\\n",
    "# Content_length:0 \\n \\\n",
    "# URL: http://localhost:8080/tienda1/miembros/editar.jsp \\n \\\n",
    "# Payload: direccion=Calle+Barrio+Cura-vigo+Vello%2C+134+10%3FD \\n\")\n",
    "\n",
    "# print(xt_in[84])\n",
    "# print(\"\\n\")\n",
    "# print(yt_in[84])\n",
    "# print(\"\\n\")\n",
    "\n",
    "# print(\"Abormal Sample:\")\n",
    "# print(\"\\n\")\n",
    "# print(\" Method: 0\\n \\\n",
    "# Content_length:0 \\n \\\n",
    "# URL: http://localhost:8080/tienda1/publico/caracteristicas.jsp \\n\\n \\\n",
    "# Payload: id=1sessionid%3D12312312%26+username%3D%253C%2573%2563%2572%2569%2570%2574%253E%2564%256F%2563%2575%256D%2565%256E%2574%252E%256C%256F%2563%2561%2574%2569%256F%256E%253D%2527%2568%2574%2574%2570%253A%252F%252F%2561%2574%2574%2561%2563%256B%2565%2572%2568%256F%2573%2574%252E%2565%2578%2561%256D%2570%256C%2565%252F%2563%2567%2569%252D%2562%2569%256E%252F%2563%256F%256F%256B%2569%2565%2573%2574%2565%2561%256C%252E%2563%2567%2569%253F%2527%252B%2564%256F%2563%2575%256D%2565%256E%2574%252E%2563%256F%256F%256B%2569%2565%253C%252F%2573+%2563%2572%2569%2570%2574%253E%3F \\n\\n \\\n",
    "# Payload Decoded: id 1sessionid 12312312 username script document location http attackerhost example cgi bin cookiesteal cgi document cookie s cript 0 0\")\n",
    "# print(\"\\n\")\n",
    "# print(xt_in[337])\n",
    "# print(\"\\n\")\n",
    "# print(yt_in[337])\n",
    "\n",
    "# test_xin_np = np.array([xt_in[84],xt_in[337]])\n",
    "# test_yin_np = np.array([yt_in[84],yt_in[337]])\n",
    "\n",
    "# print(\"Input Test Data:\")\n",
    "# print(type(xt_in))\n",
    "# print(len(xt_in))\n",
    "# print(type(xt_in[0]))\n",
    "# print(len(xt_in[0]))\n",
    "\n",
    "# print(\"Input Test Data:\")\n",
    "# print(type(test_xin_np))\n",
    "# print(len(test_xin_np))\n",
    "# print(type(test_xin_np[0]))\n",
    "# print(len(test_xin_np[0]))\n",
    "# print(test_xin_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "***BENIGN TRAFFIC***\n",
      "========================================================================\n",
      "***DIMENSIONS***\n",
      "Dimensions Rows: 555941 Columns: 115\n",
      "***NAN ROWS***\n",
      "[[     0]\n",
      " [ 59719]\n",
      " [112732]\n",
      " [165747]\n",
      " [223900]\n",
      " [285281]\n",
      " [342812]\n",
      " [401482]\n",
      " [455766]]\n",
      "***** NAN Removal *****\n",
      "***DIMENSIONS***\n",
      "Dimensions Rows: 555932 Columns: 115\n",
      "***NAN ROWS***\n",
      "[]\n",
      "========================================================================\n",
      "***MALICIOUS TRAFFIC***\n",
      "========================================================================\n",
      "***DIMENSIONS***\n",
      "Dimensions Rows: 515165 Columns: 115\n",
      "***NAN ROWS***\n",
      "[[     0]\n",
      " [ 59719]\n",
      " [112732]\n",
      " [165747]\n",
      " [223900]\n",
      " [285281]\n",
      " [342812]\n",
      " [401482]\n",
      " [455766]]\n",
      "***** NAN Removal *****\n",
      "***DIMENSIONS***\n",
      "Dimensions Rows: 515156 Columns: 115\n",
      "***NAN ROWS***\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# DELETE COLUMNS WITH NAN\n",
    "print(\"========================================================================\")\n",
    "print(\"***BENIGN TRAFFIC***\")\n",
    "print(\"========================================================================\")\n",
    "print(\"***DIMENSIONS***\")\n",
    "numrows = len(benign_traffic)\n",
    "numcols = len(benign_traffic[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))\n",
    "\n",
    "print(\"***NAN ROWS***\")\n",
    "nan_rows=np.argwhere(np.isnan(gafgyt_combo).any(axis=1))\n",
    "print(nan_rows)\n",
    "\n",
    "print(\"***** NAN Removal *****\")\n",
    "benign_traffic = benign_traffic[~np.isnan(benign_traffic).any(axis=1)]\n",
    "\n",
    "print(\"***DIMENSIONS***\")\n",
    "numrows_good = len(benign_traffic)\n",
    "numcols = len(benign_traffic[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows_good,numcols))\n",
    "\n",
    "print(\"***NAN ROWS***\")\n",
    "nan_rows=np.argwhere(np.isnan(benign_traffic).any(axis=1))\n",
    "print(nan_rows)\n",
    "\n",
    "print(\"========================================================================\")\n",
    "print(\"***MALICIOUS TRAFFIC***\")\n",
    "print(\"========================================================================\")\n",
    "print(\"***DIMENSIONS***\")\n",
    "malicious_dataset = gafgyt_combo\n",
    "\n",
    "numrows = len(malicious_dataset)\n",
    "numcols = len(malicious_dataset[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))\n",
    "\n",
    "print(\"***NAN ROWS***\")\n",
    "nan_rows=np.argwhere(np.isnan(malicious_dataset).any(axis=1))\n",
    "print(nan_rows)\n",
    "\n",
    "print(\"***** NAN Removal *****\")\n",
    "malicious_dataset = malicious_dataset[~np.isnan(malicious_dataset).any(axis=1)]\n",
    "\n",
    "print(\"***DIMENSIONS***\")\n",
    "numrows_bad = len(malicious_dataset)\n",
    "numcols = len(malicious_dataset[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows_bad,numcols))\n",
    "print(\"***NAN ROWS***\")\n",
    "nan_rows=np.argwhere(np.isnan(malicious_dataset).any(axis=1))\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 1.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 1.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 1.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 1.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 1.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 6.00000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 6.00000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.50566169e+09, 0.00000000e+00,\n",
       "        1.00000000e+00, 1.50566169e+09, 0.00000000e+00, 1.00000000e+00,\n",
       "        1.50566169e+09, 0.00000000e+00, 1.00000000e+00, 1.50566169e+09,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.50566169e+09, 0.00000000e+00,\n",
       "        1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 6.00000000e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 6.00000000e+01, 0.00000000e+00,\n",
       "        6.00000000e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 6.00000000e+01, 0.00000000e+00, 6.00000000e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.54000000e+02, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.54000000e+02, 0.00000000e+00, 1.00000000e+00, 3.54000000e+02,\n",
       "        0.00000000e+00, 1.00000000e+00, 3.54000000e+02, 0.00000000e+00,\n",
       "        1.00000000e+00, 3.54000000e+02, 0.00000000e+00, 1.00000003e+00,\n",
       "        3.54000000e+02, 4.59000000e-06, 1.00003178e+00, 3.53999619e+02,\n",
       "        4.57538300e-03, 1.03175707e+00, 3.53630645e+02, 4.29583941e+00,\n",
       "        2.59751522e+00, 3.46619800e+02, 3.40950471e+01, 5.31989524e+00,\n",
       "        3.44262695e+02, 2.21882986e+01, 1.00000003e+00, 3.54000000e+02,\n",
       "        2.14251900e-03, 3.54000000e+02, 4.59000000e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00003178e+00, 3.53999619e+02, 6.76415740e-02,\n",
       "        3.53999619e+02, 4.57538300e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.03175707e+00, 3.53630645e+02, 2.07264069e+00, 3.53630645e+02,\n",
       "        4.29583941e+00, 0.00000000e+00, 0.00000000e+00, 2.59751522e+00,\n",
       "        3.46619800e+02, 5.83909643e+00, 3.46619800e+02, 3.40950471e+01,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.31989524e+00, 3.44262695e+02,\n",
       "        4.71044569e+00, 3.44262695e+02, 2.21882986e+01, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000003e+00, 4.98057520e+00, 4.23000000e-07,\n",
       "        1.00003178e+00, 4.98069089e+00, 4.22029000e-04, 1.03175707e+00,\n",
       "        5.09251142e+00, 4.18370441e-01, 2.59751522e+00, 3.12448488e+01,\n",
       "        6.97610498e+03, 5.31989524e+00, 5.80165110e+01, 1.27406361e+04,\n",
       "        1.00000003e+00, 3.54000000e+02, 2.14251900e-03, 3.54000000e+02,\n",
       "        4.59000000e-06, 0.00000000e+00, 0.00000000e+00, 1.00003178e+00,\n",
       "        3.53999619e+02, 6.76415740e-02, 3.53999619e+02, 4.57538300e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.03175707e+00, 3.53630645e+02,\n",
       "        2.07264069e+00, 3.53630645e+02, 4.29583941e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.59751522e+00, 3.46619800e+02, 5.83909643e+00,\n",
       "        3.46619800e+02, 3.40950471e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.31989524e+00, 3.44262695e+02, 4.71044569e+00, 3.44262695e+02,\n",
       "        2.21882986e+01, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign_traffic[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE UNWANTED COLUMNS\n",
    "benign_traffic = np.delete(benign_traffic, [2,5,8,11,14,17,20,23,26,29,\\\n",
    "                                            34,35,41,42,48,49,55,56,62,63,\\\n",
    "                                            66,67,69,70,72,73,75,76,78,79,\\\n",
    "                                            84,85,91,92,98,99,105,106,112,113,], axis=1)\n",
    "malicious_dataset = np.delete(malicious_dataset, [2,5,8,11,14,17,20,23,26,29,\\\n",
    "                                            34,35,41,42,48,49,55,56,62,63,\\\n",
    "                                            66,67,69,70,72,73,75,76,78,79,\\\n",
    "                                            84,85,91,92,98,99,105,106,112,113,], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***DIMENSIONS BENIGN***\n",
      "Dimensions Rows: 555932 Columns: 75\n",
      "***DIMENSIONS MALICIOUS***\n",
      "Dimensions Rows: 515156 Columns: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"***DIMENSIONS BENIGN***\")\n",
    "numrows_good = len(benign_traffic)\n",
    "numcols_good = len(benign_traffic[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows_good,numcols_good))\n",
    "print(\"***DIMENSIONS MALICIOUS***\")\n",
    "numrows_bad = len(malicious_dataset)\n",
    "numcols_bad = len(malicious_dataset[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows_bad,numcols_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** COMPLETE DATASET ***\n",
      "Dimensions Rows: 1071088 Columns: 75\n"
     ]
    }
   ],
   "source": [
    "complete_dataset = np.concatenate((benign_traffic, malicious_dataset), 0)\n",
    "print(\"*** COMPLETE DATASET ***\")\n",
    "numrows = len(complete_dataset)\n",
    "numcols = len(complete_dataset[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATASET\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataX_ = scaler.fit_transform(complete_dataset)\n",
    "#dataX_ = scaler.fit_transform(np.reshape(complete_dataset, (numrows, numcols)))\n",
    "#                                                        (5000,100*75)\n",
    "X_ = dataX_\n",
    "#X_ = np.reshape(dataX_, (numrows, numcols))\n",
    "#X_ = np.reshape(dataX_, (5000, 100, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** COMPLETE DATASET ***\n",
      "Dimensions Rows: 555932 Columns: 75\n",
      "*** COMPLETE DATASET ***\n",
      "Dimensions Rows: 515156 Columns: 75\n"
     ]
    }
   ],
   "source": [
    "benign_traffic = X_[:numrows_good, :]\n",
    "malicious_dataset = X_[numrows_good:, :]\n",
    "\n",
    "print(\"*** COMPLETE DATASET ***\")\n",
    "numrows = len(benign_traffic)\n",
    "numcols = len(benign_traffic[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))\n",
    "\n",
    "print(\"*** COMPLETE DATASET ***\")\n",
    "numrows = len(malicious_dataset)\n",
    "numcols = len(malicious_dataset[0])\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))\n",
    "\n",
    "# Clear Variables\n",
    "del X_\n",
    "del dataX_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444746\n",
      "412125\n"
     ]
    }
   ],
   "source": [
    "def rounder(x):\n",
    "    if (x-int(x) >= 0.5):\n",
    "        return np.ceil(x)\n",
    "    else:\n",
    "        return np.floor(x)\n",
    "\n",
    "split1 = int(rounder(len(benign_traffic)*0.8))\n",
    "split2 = int(rounder(len(malicious_dataset)*0.8))\n",
    "current_bot_data = gafgyt_combo\n",
    "\n",
    "print(split1)\n",
    "print(split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** DIMENSIONS benign_pre_train_x***\n",
      "Dimensions Rows: 444746 Columns: 75\n",
      "*** DIMENSIONS benign_pre_test_x***\n",
      "Dimensions Rows: 111186 Columns: 75\n",
      "*** DIMENSIONS benign_pre_train_y***\n",
      "Dimensions Rows: 444746 Columns: 75\n",
      "*** DIMENSIONS benign_pre_test_y***\n",
      "Dimensions Rows: 111186 Columns: 75\n",
      "*** DIMENSIONS malicious_pre_train_x***\n",
      "Dimensions Rows: 412125 Columns: 75\n",
      "*** DIMENSIONS malicious_pre_test_x***\n",
      "Dimensions Rows: 103031 Columns: 75\n",
      "*** DIMENSIONS malicious_pre_train_y***\n",
      "Dimensions Rows: 412125 Columns: 75\n",
      "*** DIMENSIONS malicious_pre_test_y***\n",
      "Dimensions Rows: 103031 Columns: 75\n",
      "*** DIMENSIONS - TRAIN_X ***\n",
      "Dimensions Rows: 856871 Columns: 75\n",
      "*** DIMENSIONS TEXT_X ***\n",
      "Dimensions Rows: 214217 Columns: 75\n",
      "*** DIMENSIONS TRAIN_Y ***\n",
      "Dimensions Rows: 856871 Columns: 75\n",
      "*** DIMENSIONS TEST_Y***\n",
      "Dimensions Rows: 214217 Columns: 75\n"
     ]
    }
   ],
   "source": [
    "# benign_traffic = np.delete(benign_traffic, [0,49549,62663,101764,277005,339160,437675,489826,526412], axis=0)\n",
    "# gafgyt_combo = np.delete(gafgyt_combo, [0,59719,112732,165747,223900,285281,334812,401482,455766], axis=0)\n",
    "# gafgyt_junk = np.delete(gafgyt_junk, [0,29069,59382,89180,117530,148429,177498,205804,234384], axis=0)\n",
    "# gafgyt_scan = np.delete(gafgyt_scan, [0,29850,57345,85466,113326,142624,171022,198721,226547], axis=0)\n",
    "# gafgyt_tcp = np.delete(gafgyt_tcp, [0,92142,187164,288701,381283,485794,575182,672966,761783], axis=0)\n",
    "# gafgyt_udp = np.delete(gafgyt_udp, [0,105875,210667,314601,420384,524396,629055,739673,843394], axis=0)\n",
    "# mirai_ack = np.delete(mirai_ack, [0,102196,215482,306606,367161,425159,536640], axis=0)\n",
    "# mirai_scan = np.delete(mirai_scan, [0,107686,150879,254501,351283,448380,494311], axis=0)\n",
    "# mirai_syn = np.delete(mirai_syn, [0,122574,239382,357511,423258,485110,610826], axis=0)\n",
    "# mirai_udp = np.delete(mirai_udp, [0,], axis=0)\n",
    "# mirai_udpplain = np.delete(mirai_udpplain, [0,], axis=0)\n",
    "\n",
    "def dimensions_data(x):\n",
    "    numrows = len(x)\n",
    "    numcols = len(x[0])\n",
    "    print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))\n",
    "\n",
    "y_benings = np.zeros(len(benign_traffic),dtype=int)\n",
    "y_malicious = np.ones(len(malicious_dataset),dtype=int)\n",
    "\n",
    "benign_pre_train_x = benign_traffic[:split1, :]\n",
    "print(\"*** DIMENSIONS benign_pre_train_x***\")\n",
    "dimensions_data(benign_pre_train_x)\n",
    "\n",
    "benign_pre_test_x = benign_traffic[split1:, :]\n",
    "print(\"*** DIMENSIONS benign_pre_test_x***\")\n",
    "dimensions_data(benign_pre_test_x)\n",
    "\n",
    "benign_pre_train_y = benign_traffic[:split1, :]\n",
    "print(\"*** DIMENSIONS benign_pre_train_y***\")\n",
    "dimensions_data(benign_pre_train_y)\n",
    "\n",
    "benign_pre_test_y = benign_traffic[split1:, :]\n",
    "print(\"*** DIMENSIONS benign_pre_test_y***\")\n",
    "dimensions_data(benign_pre_test_y)\n",
    "\n",
    "\n",
    "\n",
    "malicious_pre_train_x = malicious_dataset[:split2, :]\n",
    "print(\"*** DIMENSIONS malicious_pre_train_x***\")\n",
    "dimensions_data(malicious_pre_train_x\n",
    "               )\n",
    "malicious_pre_test_x = malicious_dataset[split2:, :]\n",
    "print(\"*** DIMENSIONS malicious_pre_test_x***\")\n",
    "dimensions_data(malicious_pre_test_x)\n",
    "\n",
    "malicious_pre_train_y = malicious_dataset[:split2, :]\n",
    "print(\"*** DIMENSIONS malicious_pre_train_y***\")\n",
    "dimensions_data(malicious_pre_train_y)\n",
    "\n",
    "malicious_pre_test_y = malicious_dataset[split2:, :]\n",
    "print(\"*** DIMENSIONS malicious_pre_test_y***\")\n",
    "dimensions_data(malicious_pre_test_y)\n",
    "\n",
    "train_x = np.concatenate((benign_pre_train_x, malicious_pre_train_x), 0)\n",
    "print(\"*** DIMENSIONS - TRAIN_X ***\")\n",
    "dimensions_data(train_x)\n",
    "    \n",
    "test_x = np.concatenate((benign_pre_test_x, malicious_pre_test_x), 0)\n",
    "print(\"*** DIMENSIONS TEXT_X ***\")\n",
    "dimensions_data(test_x)\n",
    "\n",
    "train_y = np.concatenate((benign_pre_train_y,malicious_pre_train_y),0)\n",
    "print(\"*** DIMENSIONS TRAIN_Y ***\")\n",
    "dimensions_data(train_y)\n",
    "\n",
    "test_y = np.concatenate((benign_pre_test_y,malicious_pre_test_y),0)\n",
    "print(\"*** DIMENSIONS TEST_Y***\")\n",
    "dimensions_data(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.27885519e-01 0.00000000e+00 6.93889390e-18 0.00000000e+00\n",
      "  0.00000000e+00 4.23431207e-01 0.00000000e+00 6.93889390e-18\n",
      "  0.00000000e+00 0.00000000e+00 4.05812719e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.73886056e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.93889390e-18\n",
      "  0.00000000e+00 0.00000000e+00 3.70234072e-01 0.00000000e+00\n",
      "  6.93889390e-18 0.00000000e+00 0.00000000e+00 3.70841959e-01\n",
      "  0.00000000e+00 6.93889390e-18 0.00000000e+00 0.00000000e+00\n",
      "  3.66963499e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.64942629e-01 0.00000000e+00 2.08166817e-17\n",
      "  0.00000000e+00 0.00000000e+00 4.44787454e-01]\n",
      " [0.00000000e+00 2.11101180e-01 0.00000000e+00 2.11399766e-01\n",
      "  0.00000000e+00 2.13965140e-01 0.00000000e+00 2.19077035e-01\n",
      "  0.00000000e+00 2.22081959e-01 1.05477549e-10 2.11101180e-01\n",
      "  7.80916051e-08 2.11399492e-01 3.41625371e-05 2.13696334e-01\n",
      "  2.00612924e-04 2.13577605e-01 1.00999460e-04 2.14726585e-01\n",
      "  1.05508723e-10 2.08510638e-01 3.11185139e-06 1.62496011e-01\n",
      "  4.27885519e-01 7.81533785e-08 2.08510368e-01 9.77359398e-05\n",
      "  1.69051279e-01 4.23431207e-01 3.42147651e-05 2.08248684e-01\n",
      "  2.99340590e-03 2.08248684e-01 4.05812719e-01 2.01097415e-04\n",
      "  2.03276454e-01 8.60642332e-03 2.03276454e-01 3.73886056e-01\n",
      "  1.01307180e-04 2.01604748e-01 6.94309159e-03 2.01604748e-01\n",
      "  3.84832906e-01 1.05508723e-10 7.81533785e-08 3.42147651e-05\n",
      "  2.01097415e-04 1.01307180e-04 1.42742006e-10 2.08510638e-01\n",
      "  3.11185139e-06 1.62496011e-01 3.70234072e-01 1.16066219e-07\n",
      "  2.08510368e-01 9.77359398e-05 1.69051279e-01 3.70841959e-01\n",
      "  7.80914788e-05 2.08248684e-01 2.99340590e-03 2.08248684e-01\n",
      "  3.66963499e-01 2.51658664e-03 2.03276454e-01 8.50720814e-03\n",
      "  2.03276454e-01 3.64942629e-01 5.78107267e-03 2.01604748e-01\n",
      "  6.91694160e-03 2.01604748e-01 4.44787454e-01]\n",
      " [2.82771642e-03 2.15738930e-01 2.24161284e-03 2.15912312e-01\n",
      "  1.04326545e-03 2.18398708e-01 1.25193684e-04 2.23554849e-01\n",
      "  2.33729047e-05 2.26614938e-01 2.82771651e-03 2.15738929e-01\n",
      "  2.24168407e-03 2.15912113e-01 1.07639650e-03 2.18196012e-01\n",
      "  3.25192499e-04 2.17600754e-01 1.24341404e-04 2.17325391e-01\n",
      "  2.82855227e-03 2.13091475e-01 8.68902453e-03 1.66065937e-01\n",
      "  4.27885519e-01 2.24345733e-03 2.12961316e-01 8.66084106e-03\n",
      "  1.72659917e-01 4.23431207e-01 1.07804211e-03 2.12633654e-01\n",
      "  9.17964401e-03 2.12633654e-01 4.05812719e-01 3.25977857e-04\n",
      "  2.07105560e-01 1.47453127e-02 2.07105560e-01 3.73886056e-01\n",
      "  1.24720241e-04 2.04044742e-01 1.33168865e-02 2.04044742e-01\n",
      "  3.84832906e-01 2.82855227e-03 2.24345733e-03 1.07804211e-03\n",
      "  3.25977857e-04 1.24720241e-04 3.82672836e-03 2.13091475e-01\n",
      "  8.68902453e-03 1.66065937e-01 3.70234072e-01 3.33177673e-03\n",
      "  2.12961316e-01 8.66084106e-03 1.72659917e-01 3.70841959e-01\n",
      "  2.46051382e-03 2.12633654e-01 9.17964401e-03 2.12633654e-01\n",
      "  3.66963499e-01 4.07937377e-03 2.07105560e-01 1.45753282e-02\n",
      "  2.07105560e-01 3.64942629e-01 7.11713405e-03 2.04044742e-01\n",
      "  1.32667306e-02 2.04044742e-01 4.44787454e-01]\n",
      " [0.00000000e+00 1.98894650e-01 0.00000000e+00 1.99175970e-01\n",
      "  0.00000000e+00 2.01593006e-01 0.00000000e+00 2.06409316e-01\n",
      "  0.00000000e+00 2.09240485e-01 0.00000000e+00 1.98894650e-01\n",
      "  0.00000000e+00 1.99175970e-01 0.00000000e+00 2.01593006e-01\n",
      "  0.00000000e+00 2.06409316e-01 0.00000000e+00 2.09240485e-01\n",
      "  0.00000000e+00 1.96453901e-01 0.00000000e+00 1.53099983e-01\n",
      "  4.27885519e-01 0.00000000e+00 1.96453901e-01 0.00000000e+00\n",
      "  1.59276411e-01 4.23431207e-01 0.00000000e+00 1.96453901e-01\n",
      "  0.00000000e+00 1.96453901e-01 4.05812719e-01 0.00000000e+00\n",
      "  1.96453901e-01 0.00000000e+00 1.96453901e-01 3.73886056e-01\n",
      "  0.00000000e+00 1.96453901e-01 0.00000000e+00 1.96453901e-01\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.96453901e-01\n",
      "  0.00000000e+00 1.53099983e-01 3.70234072e-01 0.00000000e+00\n",
      "  1.96453901e-01 0.00000000e+00 1.59276411e-01 3.70841959e-01\n",
      "  0.00000000e+00 1.96453901e-01 0.00000000e+00 1.96453901e-01\n",
      "  3.66963499e-01 0.00000000e+00 1.96453901e-01 0.00000000e+00\n",
      "  1.96453901e-01 3.64942629e-01 0.00000000e+00 1.96453901e-01\n",
      "  0.00000000e+00 1.96453901e-01 4.44787454e-01]\n",
      " [2.24213249e-03 8.05206802e-02 1.95027501e-03 8.81265796e-02\n",
      "  9.95955439e-04 9.69143844e-02 1.24614026e-04 1.02806976e-01\n",
      "  2.33620602e-05 1.04579929e-01 2.24213249e-03 8.05206802e-02\n",
      "  1.95027501e-03 8.81265796e-02 9.95955439e-04 9.69143844e-02\n",
      "  1.24614026e-04 1.02806976e-01 2.33620602e-05 1.04579929e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.56677178e-01\n",
      "  4.27885519e-01 0.00000000e+00 6.93889390e-18 0.00000000e+00\n",
      "  2.43276182e-01 4.23431207e-01 0.00000000e+00 6.93889390e-18\n",
      "  0.00000000e+00 2.68015660e-01 4.05812719e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.55006142e-01 3.73886056e-01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.53796690e-01\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.93889390e-18\n",
      "  0.00000000e+00 0.00000000e+00 3.70234072e-01 0.00000000e+00\n",
      "  6.93889390e-18 0.00000000e+00 0.00000000e+00 3.70841959e-01\n",
      "  0.00000000e+00 6.93889390e-18 0.00000000e+00 0.00000000e+00\n",
      "  3.66963499e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.64942629e-01 0.00000000e+00 2.08166817e-17\n",
      "  0.00000000e+00 0.00000000e+00 4.44787454e-01]\n",
      " [5.28731378e-03 5.31842028e-02 4.28687452e-03 5.94207884e-02\n",
      "  2.05257369e-03 6.68415082e-02 2.49960162e-04 7.16681530e-02\n",
      "  4.67377964e-05 7.29832025e-02 5.28731378e-03 5.31842028e-02\n",
      "  4.28687452e-03 5.94207884e-02 2.05257369e-03 6.68415082e-02\n",
      "  2.49960162e-04 7.16681530e-02 4.67377964e-05 7.29832025e-02\n",
      "  3.14772320e-03 4.71681033e-03 9.43823454e-03 1.66065484e-02\n",
      "  4.21986844e-01 2.39201235e-03 4.67406518e-03 9.39100150e-03\n",
      "  2.11116331e-02 3.99727639e-01 1.06744311e-03 4.63130901e-03\n",
      "  9.38750708e-03 1.05730687e-01 3.25122758e-01 1.25764667e-04\n",
      "  4.61206709e-03 9.58054833e-03 1.85795177e-01 2.92068994e-01\n",
      "  2.34491296e-05 4.61014288e-03 9.58085462e-03 1.92056169e-01\n",
      "  3.08644435e-01 3.14772320e-03 2.39201235e-03 1.06744311e-03\n",
      "  1.25764667e-04 2.34491296e-05 0.00000000e+00 9.21985816e-03\n",
      "  0.00000000e+00 7.18519776e-03 3.70234072e-01 0.00000000e+00\n",
      "  9.21985816e-03 0.00000000e+00 7.47506623e-03 3.70841959e-01\n",
      "  0.00000000e+00 9.21985816e-03 0.00000000e+00 9.21985816e-03\n",
      "  3.66963499e-01 0.00000000e+00 9.21985816e-03 0.00000000e+00\n",
      "  9.21985816e-03 3.64942629e-01 0.00000000e+00 9.21985816e-03\n",
      "  0.00000000e+00 9.21985816e-03 4.44787454e-01]\n",
      " [6.93455663e-03 4.29892615e-02 5.93415474e-03 4.83363694e-02\n",
      "  2.99765804e-03 5.49552517e-02 3.73939453e-04 5.92708366e-02\n",
      "  7.00879589e-05 6.03957245e-02 6.93455663e-03 4.29892615e-02\n",
      "  5.93415474e-03 4.83363694e-02 2.99765804e-03 5.49552517e-02\n",
      "  3.73939453e-04 5.92708366e-02 7.00879589e-05 6.03957245e-02\n",
      "  0.00000000e+00 2.12765957e-02 0.00000000e+00 1.65812256e-02\n",
      "  4.27885519e-01 0.00000000e+00 2.12765957e-02 0.00000000e+00\n",
      "  1.72501528e-02 4.23431207e-01 0.00000000e+00 2.12765957e-02\n",
      "  0.00000000e+00 2.12765957e-02 4.05812719e-01 0.00000000e+00\n",
      "  2.12765957e-02 0.00000000e+00 2.12765957e-02 3.73886056e-01\n",
      "  0.00000000e+00 2.12765957e-02 0.00000000e+00 2.12765957e-02\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.12765957e-02\n",
      "  0.00000000e+00 1.65812256e-02 3.70234072e-01 0.00000000e+00\n",
      "  2.12765957e-02 0.00000000e+00 1.72501528e-02 3.70841959e-01\n",
      "  0.00000000e+00 2.12765957e-02 0.00000000e+00 2.12765957e-02\n",
      "  3.66963499e-01 0.00000000e+00 2.12765957e-02 0.00000000e+00\n",
      "  2.12765957e-02 3.64942629e-01 0.00000000e+00 2.12765957e-02\n",
      "  0.00000000e+00 2.12765957e-02 4.44787454e-01]\n",
      " [1.04379316e-04 1.66965499e-01 5.35890052e-04 1.49149999e-01\n",
      "  1.62816732e-03 1.02002590e-01 4.55748144e-04 8.47778825e-02\n",
      "  9.26148243e-05 8.44590911e-02 1.04379316e-04 1.66965499e-01\n",
      "  5.35890052e-04 1.49149999e-01 1.62816732e-03 1.02002590e-01\n",
      "  4.55748144e-04 8.47778825e-02 9.26148243e-05 8.44590911e-02\n",
      "  0.00000000e+00 1.68794326e-01 0.00000000e+00 1.31544390e-01\n",
      "  4.27885519e-01 0.00000000e+00 1.68794326e-01 0.00000000e+00\n",
      "  1.36851213e-01 4.23431207e-01 0.00000000e+00 1.68794326e-01\n",
      "  0.00000000e+00 1.68794326e-01 4.05812719e-01 0.00000000e+00\n",
      "  1.68794326e-01 0.00000000e+00 1.68794326e-01 3.73886056e-01\n",
      "  0.00000000e+00 1.68794326e-01 0.00000000e+00 1.68794326e-01\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.68794326e-01\n",
      "  0.00000000e+00 1.31544390e-01 3.70234072e-01 0.00000000e+00\n",
      "  1.68794326e-01 0.00000000e+00 1.36851213e-01 3.70841959e-01\n",
      "  0.00000000e+00 1.68794326e-01 0.00000000e+00 1.68794326e-01\n",
      "  3.66963499e-01 0.00000000e+00 1.68794326e-01 0.00000000e+00\n",
      "  1.68794326e-01 3.64942629e-01 0.00000000e+00 1.68794326e-01\n",
      "  0.00000000e+00 1.68794326e-01 4.44787454e-01]\n",
      " [9.26883957e-09 4.69484717e-07 1.37229727e-06 8.32384422e-05\n",
      "  2.08489671e-04 1.65596472e-02 4.49913588e-04 6.62784923e-02\n",
      "  1.13060213e-04 6.99863890e-02 9.26883957e-09 4.69484717e-07\n",
      "  1.37229727e-06 8.32384422e-05 2.08489671e-04 1.65596472e-02\n",
      "  4.49913588e-04 6.62784923e-02 1.13060213e-04 6.99863890e-02\n",
      "  1.45074495e-10 2.05673756e-10 2.83007774e-06 1.37363378e-02\n",
      "  4.69391457e-01 1.24965226e-07 2.37475177e-07 9.53287412e-05\n",
      "  1.42913773e-02 4.36704111e-01 6.33429018e-05 2.57168390e-04\n",
      "  3.09163830e-03 2.17015635e-02 3.44453207e-01 1.76937767e-04\n",
      "  2.69483905e-03 8.71472082e-03 1.20024371e-01 2.71119800e-01\n",
      "  4.52772361e-05 3.03708656e-03 9.00596372e-03 1.35671283e-01\n",
      "  2.76685972e-01 1.45074495e-10 1.24965226e-07 6.33429018e-05\n",
      "  1.76937767e-04 4.52772361e-05 0.00000000e+00 6.93889390e-18\n",
      "  0.00000000e+00 1.37363370e-02 3.70234072e-01 0.00000000e+00\n",
      "  6.93889390e-18 0.00000000e+00 1.42904945e-02 3.70841959e-01\n",
      "  0.00000000e+00 6.93889390e-18 0.00000000e+00 1.76261090e-02\n",
      "  3.66963499e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.76261090e-02 3.64942629e-01 0.00000000e+00 2.08166817e-17\n",
      "  0.00000000e+00 1.76261090e-02 4.44787454e-01]\n",
      " [2.96537684e-03 6.80390450e-03 2.30774988e-03 6.71518582e-03\n",
      "  1.25735638e-03 1.49644314e-02 5.74275682e-04 5.67925635e-02\n",
      "  1.36411427e-04 6.17356913e-02 2.96537684e-03 6.80390450e-03\n",
      "  2.30774988e-03 6.71518582e-03 1.25735638e-03 1.49644314e-02\n",
      "  5.74275682e-04 5.67925635e-02 1.36411427e-04 6.17356913e-02\n",
      "  0.00000000e+00 1.27659574e-02 0.00000000e+00 9.94873536e-03\n",
      "  4.27885519e-01 0.00000000e+00 1.27659574e-02 0.00000000e+00\n",
      "  1.03500917e-02 4.23431207e-01 0.00000000e+00 1.27659574e-02\n",
      "  0.00000000e+00 1.27659574e-02 4.05812719e-01 0.00000000e+00\n",
      "  1.27659574e-02 0.00000000e+00 1.27659574e-02 3.73886056e-01\n",
      "  0.00000000e+00 1.27659574e-02 0.00000000e+00 1.27659574e-02\n",
      "  3.84832906e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.27659574e-02\n",
      "  0.00000000e+00 9.94873536e-03 3.70234072e-01 0.00000000e+00\n",
      "  1.27659574e-02 0.00000000e+00 1.03500917e-02 3.70841959e-01\n",
      "  0.00000000e+00 1.27659574e-02 0.00000000e+00 1.27659574e-02\n",
      "  3.66963499e-01 0.00000000e+00 1.27659574e-02 0.00000000e+00\n",
      "  1.27659574e-02 3.64942629e-01 0.00000000e+00 1.27659574e-02\n",
      "  0.00000000e+00 1.27659574e-02 4.44787454e-01]]\n",
      "Dimensions Rows: 555932 Columns: 75\n"
     ]
    }
   ],
   "source": [
    "#benign_traffic[~np.isnan(benign_traffic).any(axis=1)]\n",
    "print(benign_traffic[0:10])\n",
    "numrows = len(benign_traffic)    # 3 rows in your example\n",
    "numcols = len(benign_traffic[0]) # 2 columns in your example\n",
    "print(\"Dimensions Rows: %s Columns: %s\" %(numrows,numcols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hm_epochs = 30\n",
    "n_classes = 2\n",
    "batch_size = 10\n",
    "chunk_size = 1 # Changed\n",
    "n_chunks = 75 # Number of attributes in dataset\n",
    "rnn_size = 1\n",
    "\n",
    "x = tf.placeholder(\"float\", shape=[None, n_chunks, chunk_size])\n",
    "y = tf.placeholder(\"float\")\n",
    "x_t = tf.placeholder(\"float\", shape=[None, n_chunks, chunk_size])\n",
    "y_t = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# x_request = tf.reshape(x, [-1,28,1,1])\n",
    "# print (\"x_request=\")\n",
    "# print (x_request)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n    relative to /home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python:\n\n    ops/rnn_cell_impl.py:766 call *\n        gate_inputs = math_ops.matmul(\n    util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    ops/math_ops.py:2569 matmul\n        with ops.name_scope(name, \"MatMul\", [a, b]) as name:\n    framework/ops.py:6508 __enter__\n        g = _get_graph_from_inputs(self._values)\n    framework/ops.py:6135 _get_graph_from_inputs\n        _assert_same_graph(original_graph_element, graph_element)\n    framework/ops.py:6071 _assert_same_graph\n        (item, original_item))\n\n    ValueError: Tensor(\"rnn/basic_lstm_cell/kernel:0\", shape=(26, 100), dtype=float32_ref) must be from the same graph as Tensor(\"concat:0\", shape=(?, 26), dtype=float32).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d67243386e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m#print('Test Abnormal:',accuracy.eval({x_t:test_xin_np.reshape((-1, n_chunks, chunk_size)), y_t:test_yin_np}))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-d67243386e30>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-d67243386e30>\u001b[0m in \u001b[0;36mrecurrent_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#     print(lstm_cell)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlstm_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#Helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1436\u001b[0m             state_size=cell.state_size)\n\u001b[1;32m   1437\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;31m# Keras RNN cells only return state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mvarscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m       \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n    relative to /home/ubuntu/.local/lib/python3.5/site-packages/tensorflow/python:\n\n    ops/rnn_cell_impl.py:766 call *\n        gate_inputs = math_ops.matmul(\n    util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    ops/math_ops.py:2569 matmul\n        with ops.name_scope(name, \"MatMul\", [a, b]) as name:\n    framework/ops.py:6508 __enter__\n        g = _get_graph_from_inputs(self._values)\n    framework/ops.py:6135 _get_graph_from_inputs\n        _assert_same_graph(original_graph_element, graph_element)\n    framework/ops.py:6071 _assert_same_graph\n        (item, original_item))\n\n    ValueError: Tensor(\"rnn/basic_lstm_cell/kernel:0\", shape=(26, 100), dtype=float32_ref) must be from the same graph as Tensor(\"concat:0\", shape=(?, 26), dtype=float32).\n"
     ]
    }
   ],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, requests, labels):\n",
    "        assert requests.shape[0] == labels.shape[0], (\"requests.shape: %s labels.shape: %s\" % (requests.shape,\n",
    "                                                 labels.shape))\n",
    "        self._num_examples = requests.shape[0]\n",
    "        # Convert shape from [num examples, rows, columns, depth]\n",
    "        # to [num examples, rows*columns] (assuming depth == 1)\n",
    "        requests = requests.reshape(requests.shape[0],\n",
    "                              requests.shape[1])\n",
    "        self._requests = requests\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            #print(\"=== Current Perm ===\")\n",
    "            #print(\"=== index_in_epoch === : %s\" % self._index_in_epoch)\n",
    "            perm = np.arange(self._num_examples)\n",
    "            #print(perm)\n",
    "            np.random.shuffle(perm)\n",
    "            self._requests = self._requests[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._requests[start:end], self._labels[start:end]\n",
    "\n",
    "current_data = DataSet(train_x, train_y)\n",
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size, n_classes])),\n",
    "             'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    x = tf.transpose(x, [1,0,2])\n",
    "    x = tf.reshape(x, [-1, chunk_size])\n",
    "    x = tf.split(x, n_chunks, 0)\n",
    "#     def make_cell():\n",
    "        \n",
    "#         lstm_cell = rnn_cell.BasicLSTMCell(rnn_size)\n",
    "#         return lstm_cell\n",
    "    \n",
    "#     lstm_cell = tf.contrib.rnn.MultiRNNCell(\n",
    "#     [make_cell for _ in range(2)], state_is_tuple=True)\n",
    "#     print(lstm_cell)\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size) \n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    \n",
    "    #Helper\n",
    "    #Decoder\n",
    "    # +  = dynamic\n",
    "    output, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    output = tf.matmul(output[-1],layer['weights']) + layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(plogits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(current_data._num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = current_data.next_batch(batch_size)\n",
    "                epoch_x = epoch_x.reshape((batch_size, n_chunks, chunk_size))\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:test_x.reshape((-1, n_chunks, chunk_size)), y:test_y}))\n",
    "        #print('Test Abnormal:',accuracy.eval({x_t:test_xin_np.reshape((-1, n_chunks, chunk_size)), y_t:test_yin_np}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
